{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paragraphle / chunkle\n",
    "- maybe there could be an optional hint where you see one of the most related paragraphs across all articles\n",
    "- connections-style UI?\n",
    "- genius.com?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maybe clustering will help?\n",
    "- Maybe show users a list of words that are common between all the matching passages!\n",
    "- Show cosine dist as a percentile of all the passages in the dataset?\n",
    "- Or try randomly play out a series guesses and look at the distribution of scores?\n",
    "- Have both modes. Match start or substring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\jackv\\anaconda3\\lib\\site-packages (1.73.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\jackv\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jackv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import copy\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(query):\n",
    "    conn = sqlite3.Connection('data/data.db')\n",
    "    data = pd.read_sql(query, conn).to_dict(orient='records')\n",
    "    conn.close()\n",
    "    return data\n",
    "\n",
    "def get_random_target():\n",
    "    return execute_sql(\"\"\"\n",
    "        select article_id, vector, title, url, chunk\n",
    "        from embeddings\n",
    "        join (\n",
    "            select article_id, title, url\n",
    "            from articles \n",
    "            order by random() \n",
    "            limit 1\n",
    "        ) as a\n",
    "            using(article_id)\n",
    "        join chunks \n",
    "            using (article_id)\n",
    "    \"\"\")\n",
    "\n",
    "def get_ai_target(article_id):\n",
    "     return execute_sql(f\"\"\"\n",
    "        select article_id, vector, title, url, chunk\n",
    "        from embeddings e\n",
    "        join articles a \n",
    "            using(article_id)\n",
    "        join chunks c \n",
    "            using (article_id)\n",
    "        where article_id == {article_id}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = []\n",
    "\n",
    "potential_targets = []\n",
    "with open('data/ai_targets.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        potential_targets.append(int(line.strip()))\n",
    "\n",
    "target_article_id = np.random.choice(potential_targets)\n",
    "target = get_ai_target(target_article_id)\n",
    "target_embeddings = np.array([np.frombuffer(x['vector']) for x in target])\n",
    "mean_target_embedding = target_embeddings.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "def get_matching_titles(substring):\n",
    "    substring = substring.lower().strip()\n",
    "    return execute_sql(f\"\"\"\n",
    "        select distinct article_id, title\n",
    "        from articles\n",
    "        where clean_title like '%{substring}%'\n",
    "    \"\"\")\n",
    "\n",
    "def guess(substring):\n",
    "    matches = get_matching_titles(substring)\n",
    "    if len(matches) >= 5:\n",
    "        return list(np.random.choice(matches, 5, replace=False))\n",
    "    elif len(matches) > 0:\n",
    "        return matches\n",
    "    return []\n",
    "\n",
    "def top_chunks(guess_id, mean_target_embedding, target_article_id):\n",
    "    if guess_id == target_article_id:\n",
    "        print('you got it!')\n",
    "    \n",
    "    guess_data = execute_sql(f\"\"\"\n",
    "        select c.chunk_id, c.article_id, e.vector, c.chunk, title\n",
    "        from (select * from embeddings where article_id == {guess_id}) as e\n",
    "        join (select * from chunks where article_id == {guess_id}) c\n",
    "            using (chunk_id)\n",
    "        join (select * from articles where article_id == {guess_id}) a\n",
    "            using (article_id)\n",
    "    \"\"\")\n",
    "\n",
    "    for i in range(len(guess_data)):\n",
    "        guess_data[i]['vector'] = np.frombuffer(guess_data[i]['vector'])\n",
    "        guess_data[i]['score'] = distance.cosine(guess_data[i]['vector'], mean_target_embedding)\n",
    "\n",
    "    return sorted(guess_data, key=lambda x: x['score'])[: 2]\n",
    "\n",
    "def print_text(text, line_size=100):\n",
    "    start = 0\n",
    "    end = line_size\n",
    "    while end < len(text):\n",
    "        print(text[start : end])\n",
    "        start += line_size\n",
    "        end += line_size\n",
    "    print(text[start :])\n",
    "\n",
    "def submit_guess(guess_id):\n",
    "    top = top_chunks(guess_id, mean_target_embedding, target_article_id)  \n",
    "    for row in top:\n",
    "        guesses.append(row)\n",
    "        print(f\"Score: {row['score']}\\n\")\n",
    "        print_text(row['chunk'])\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) Oceanic climate\n",
      "1) Department of Climate Change, Energy, the Environment and Water\n",
      "2) Microclimate\n",
      "3) Climate of Egypt\n",
      "4) Temperate climate\n"
     ]
    }
   ],
   "source": [
    "g = guess('climate')\n",
    "for i, x in enumerate(g):\n",
    "    print(f\"{i}) {x['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you got it!\n",
      "Score: 0.0\n",
      "\n",
      "The Department of Climate Change, Energy, the Environment and Water (DCCEEW) is a department of the \n",
      "Australian Government. The department was established on 1 July 2022, superseding the water and envi\n",
      "ronment functions from the Department of Agriculture, Water and the Environment and energy functions\n",
      " from the Department of Industry, Science, Energy and Resources. The current and inaugural head of t\n",
      "he department is the Secretary, David Fredericks. References 2022 establishments in Australia Austra\n",
      "lia, Climate Change, Energy,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "submit_guess(g[i]['article_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "University of Melbourne | Score: 0.5746451492093343\n",
      "\n",
      "of Land and Environment was disestablished on 1January 2015. Its agriculture and food systems depart\n",
      "ment moved alongside veterinary science to form the Faculty of Veterinary and Agricultural Sciences,\n",
      " while other areas of study, including horticulture, forestry, geography and resource management, mo\n",
      "ved to the Faculty of Science in two new departments. In 2019, allegations of a toxic workplace cult\n",
      "ure within the Faculty of Arts were aired, with a number of senior staff leaving their positions. At\n",
      "\n",
      "University of Melbourne | Score: 0.5990288854272678\n",
      "\n",
      "which led to the sacking of 500 administrative staff and some administrative responsibilities being \n",
      "transferred to academic staff. At the same time in the ten years to 2018 the university embarked on \n",
      "a large capital works program, spending $2 billion on new buildings across the university's campuses\n",
      ". The Melbourne School of Land and Environment was disestablished on 1January 2015. Its agriculture \n",
      "and food systems department moved alongside veterinary science to form the Faculty of Veterinary\n",
      "\n",
      "Mike Ahern (Australian politician) | Score: 0.6143059120258878\n",
      "\n",
      "Industries, Minister for Industry, Small Business and Technology, and Minister for Health and Enviro\n",
      "nment. Ahern was significantly younger than most of his Cabinet colleagues, and was one of few membe\n",
      "rs of cabinet with tertiary qualifications. By the late 1980s the standing of Sir Joh Bjelke-Peterse\n",
      "n (he was knighted in 1984) as premier had begun to be compromised by the failure of the disastrous \n",
      "\"Joh for Canberra\" campaign in 1987 and the establishment, against Bjelke-Petersen's will\n",
      "\n",
      "Mike Ahern (Australian politician) | Score: 0.6375154536142635\n",
      "\n",
      "governments in Australia. He announced plans to reform the public service and the parliament, and so\n",
      "ught to take a more consultative approach to governing. However, he resisted calls to abolish the \"B\n",
      "jelkemander,\" the rural overweighting that favoured the National Party. Ahern also brought in legisl\n",
      "ation relating to domestic violence and established the Southbank Corporation to redevelop the site \n",
      "of Expo '88 (now South Bank Parklands). Ahern oversaw the parliamentary dismissal of a Supreme Court\n",
      " of\n",
      "\n",
      "Federation University Australia | Score: 0.6388969884148055\n",
      "\n",
      "Centre Centre for Smart Analytics Centre for New Energy Transition Research Collaborative Evaluation\n",
      " and Research Group Geotechnical and Hydrogeological Engineering Research Group Notable alumni Kate \n",
      "Allen (triathlete) Martin Andanar, press secretary of the Philippines under Duterte administration A\n",
      "unty Donna, absurdist sketch comedy troupe William Baragwanath, geologist Phillip Bellingham, winter\n",
      " olympian Steve Bracks, former Premier of Victoria Sandy Blythe, wheelchair basketball player Dr Cyr\n",
      "il P. Callister, inventor of Vegemite Darren Cheeseman, politician Peter Crisp, politician Jacquelin\n",
      "e\n",
      "\n",
      "Australian Law Reform Commission | Score: 0.6451016437667811\n",
      "\n",
      "The Australian Law Reform Commission (often abbreviated to ALRC) is an Australian independent statut\n",
      "ory body established to conduct reviews into the law of Australia. The reviews, also called inquirie\n",
      "s or references, are referred to the ALRC by the Attorney-General for Australia. Based on its resear\n",
      "ch and consultations throughout an inquiry, the ALRC makes recommendations to government so that gov\n",
      "ernment can make informed decisions about law reform. The ALRC is part of the Attorney-General's por\n",
      "tfolio; however\n",
      "\n",
      "Australian Institute of Aboriginal and Torres Strait Islander Studies | Score: 0.6461578321176431\n",
      "\n",
      "portfolio of the Prime Minister and Cabinet. Council The AIATSIS Council is a governing body designe\n",
      "d to oversee and steer the functions and direction of the institute. The role and responsibilities o\n",
      "f the council are mandated in the AIATSIS Act 1989 and detailed in the AIATSIS Council Charter. The \n",
      "Council consists of nine members, four are elected by the institute's membership and five appointed \n",
      "by the Minister. According to the AIATSIS Act 1989, one person\n",
      "\n",
      "Australian Law Reform Commission | Score: 0.6478672407413729\n",
      "\n",
      "ALRC must also have regard to any effect that its recommendations may have on the costs of access to\n",
      ", and dispensing of, justice. Background The ALRC is the primary law reform agency for the Australia\n",
      "n government. It has its origins in the Law Reform Commission, which was established in 1975 under t\n",
      "he Law Reform Commission Act 1973. This legislation was superseded by the Australian Law Reform Comm\n",
      "ission Act 1996 (Cth) (the ALRC Act) which came\n",
      "\n",
      "Australian Institute of Aboriginal and Torres Strait Islander Studies | Score: 0.6618591264660318\n",
      "\n",
      "is the first Aboriginal woman, and the only woman of any descent, to have held the position of AIATS\n",
      "IS Council Chairperson. Research Advisory Committee The Research Advisory Committee (RAC) is respons\n",
      "ible for assessing and advising on AIATSIS research projects and programs, including research grants\n",
      ". The functions of the Research Advisory Committee are established in the AIATSIS Act, 1989. They ar\n",
      "e: (a) to assess applications for research grants made to the Institute and to make recommendations\n",
      "\n",
      "Australian Broadcasting Company | Score: 0.6652325893601733\n",
      "\n",
      "NSW 2FC located in Sydney, NSW 2NC located in Newcastle, NSW 3AR located in Melbourne, VIC 3LO locat\n",
      "ed in Melbourne, VIC 4QG located in Brisbane, QLD 5CL located in Adelaide, SA 6WF located in Perth, \n",
      "WA ABC Commission Acquires ABC Company on the 1st of July, 1932: Radio announcer Conrad Charlton beg\n",
      "an the day's broadcast at 2BL and/or 2FC, saying; \"This is the Australian Broadcasting Commission.\" \n",
      "At 8pm the Commission was formally opened by the\n"
     ]
    }
   ],
   "source": [
    "top_guesses = sorted(list(set([(x['score'], x['chunk'], x['title']) for x in guesses])), key=lambda x: x[0])[: 10]\n",
    "for score, text, title in top_guesses:\n",
    "    print(f'\\n{title} | Score: {score}\\n')\n",
    "    print_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) department\n",
      "2) environment\n",
      "3) established\n",
      "4) australian\n",
      "5) functions\n",
      "6) government.\n",
      "7) industry,\n",
      "8) australia,\n",
      "9) land\n",
      "10) disestablished\n"
     ]
    }
   ],
   "source": [
    "guess_words = ' '.join([x[1] for x in top_guesses]).split()\n",
    "guess_words = [x.strip().lower() for x in guess_words if x not in stop_words]\n",
    "guess_map = {token: count / len(guess_words) for token, count in Counter(guess_words).items()}\n",
    "\n",
    "target_words = [x.strip().lower() for x in ' '.join([x['chunk'] for x in target]).split()]\n",
    "target_words = [x for x in target_words if x not in stop_words]\n",
    "target_map = {token: count / len(target_words) for token, count in Counter(target_words).items()}\n",
    "\n",
    "matches = {}\n",
    "for guess_token, guess_score in guess_map.items():\n",
    "    matches[guess_token] = guess_score * target_map.get(guess_token, 0)\n",
    "\n",
    "for i, x in enumerate(list(sorted([(k, v) for k, v in matches.items()], key=lambda x: x[1], reverse=True))[: 10]):\n",
    "    print(f\"{i + 1}) {x[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = target[0]\n",
    "# print(t['title'])\n",
    "# print(t['url'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
